{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LogisticRegression.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1i11ovwXOHVtGmGW5AckGrDoEW5ZS3OYb","authorship_tag":"ABX9TyNH9u7VP+1Pge/qxUJSLM1J"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"UGZl80O6aHiO","colab_type":"text"},"source":["## import libraries"]},{"cell_type":"code","metadata":{"id":"fUTx2G60aKeM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023719943,"user_tz":-330,"elapsed":3631,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["import pandas as pd\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSqXeXI8aWD9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023719944,"user_tz":-330,"elapsed":3623,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["df = pd.read_csv('/content/drive/My Drive/machine learning/classification/data/Wine_Quality_Data.csv')"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"vq3-AA6IaWHF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"status":"ok","timestamp":1597023719945,"user_tz":-330,"elapsed":3611,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"3e5135cf-cbfb-41bb-f590-d3af4c7d8c94"},"source":["df.head()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed_acidity</th>\n","      <th>volatile_acidity</th>\n","      <th>citric_acid</th>\n","      <th>residual_sugar</th>\n","      <th>chlorides</th>\n","      <th>free_sulfur_dioxide</th>\n","      <th>total_sulfur_dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","      <th>quality</th>\n","      <th>color</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>red</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.8</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>2.6</td>\n","      <td>0.098</td>\n","      <td>25.0</td>\n","      <td>67.0</td>\n","      <td>0.9968</td>\n","      <td>3.20</td>\n","      <td>0.68</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>red</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.8</td>\n","      <td>0.76</td>\n","      <td>0.04</td>\n","      <td>2.3</td>\n","      <td>0.092</td>\n","      <td>15.0</td>\n","      <td>54.0</td>\n","      <td>0.9970</td>\n","      <td>3.26</td>\n","      <td>0.65</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>red</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.2</td>\n","      <td>0.28</td>\n","      <td>0.56</td>\n","      <td>1.9</td>\n","      <td>0.075</td>\n","      <td>17.0</td>\n","      <td>60.0</td>\n","      <td>0.9980</td>\n","      <td>3.16</td>\n","      <td>0.58</td>\n","      <td>9.8</td>\n","      <td>6</td>\n","      <td>red</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>red</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   fixed_acidity  volatile_acidity  citric_acid  ...  alcohol  quality  color\n","0            7.4              0.70         0.00  ...      9.4        5    red\n","1            7.8              0.88         0.00  ...      9.8        5    red\n","2            7.8              0.76         0.04  ...      9.8        5    red\n","3           11.2              0.28         0.56  ...      9.8        6    red\n","4            7.4              0.70         0.00  ...      9.4        5    red\n","\n","[5 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"5Y78TK8RaWMt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1597023719947,"user_tz":-330,"elapsed":3602,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"2a070d46-4ae1-447b-8a76-7690725b090c"},"source":["df.info()"],"execution_count":4,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6497 entries, 0 to 6496\n","Data columns (total 13 columns):\n"," #   Column                Non-Null Count  Dtype  \n","---  ------                --------------  -----  \n"," 0   fixed_acidity         6497 non-null   float64\n"," 1   volatile_acidity      6497 non-null   float64\n"," 2   citric_acid           6497 non-null   float64\n"," 3   residual_sugar        6497 non-null   float64\n"," 4   chlorides             6497 non-null   float64\n"," 5   free_sulfur_dioxide   6497 non-null   float64\n"," 6   total_sulfur_dioxide  6497 non-null   float64\n"," 7   density               6497 non-null   float64\n"," 8   pH                    6497 non-null   float64\n"," 9   sulphates             6497 non-null   float64\n"," 10  alcohol               6497 non-null   float64\n"," 11  quality               6497 non-null   int64  \n"," 12  color                 6497 non-null   object \n","dtypes: float64(11), int64(1), object(1)\n","memory usage: 660.0+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ExEZn_YaWPr","colab_type":"code","colab":{},"cellView":"code","executionInfo":{"status":"ok","timestamp":1597023719949,"user_tz":-330,"elapsed":3596,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["## we have 1 object column\n","\n","# we have to check how many categorical values are present"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssmkti5qaWSz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597023721761,"user_tz":-330,"elapsed":5398,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"699303c7-b729-4234-dffd-2ab3ae3ca558"},"source":["df.color.unique()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['red', 'white'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"osUhZS1AaWV9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721761,"user_tz":-330,"elapsed":5388,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["# in this the only target column is in categorical column\n","# we are going to change the column into numerical by using LabelEncoder"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"gLGuyLHgaWY_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721762,"user_tz":-330,"elapsed":5382,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["from sklearn.preprocessing import  LabelEncoder\n","encoder = LabelEncoder()"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"qsUgJXXJaWb2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721763,"user_tz":-330,"elapsed":5377,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["df.iloc[:,12]=encoder.fit_transform(df.iloc[:,12])"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"QqNN-SXgaWei","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"status":"ok","timestamp":1597023721763,"user_tz":-330,"elapsed":5370,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"49609ec9-d1b2-44a3-c8e1-55af128bcea0"},"source":["df.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fixed_acidity</th>\n","      <th>volatile_acidity</th>\n","      <th>citric_acid</th>\n","      <th>residual_sugar</th>\n","      <th>chlorides</th>\n","      <th>free_sulfur_dioxide</th>\n","      <th>total_sulfur_dioxide</th>\n","      <th>density</th>\n","      <th>pH</th>\n","      <th>sulphates</th>\n","      <th>alcohol</th>\n","      <th>quality</th>\n","      <th>color</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7.8</td>\n","      <td>0.88</td>\n","      <td>0.00</td>\n","      <td>2.6</td>\n","      <td>0.098</td>\n","      <td>25.0</td>\n","      <td>67.0</td>\n","      <td>0.9968</td>\n","      <td>3.20</td>\n","      <td>0.68</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7.8</td>\n","      <td>0.76</td>\n","      <td>0.04</td>\n","      <td>2.3</td>\n","      <td>0.092</td>\n","      <td>15.0</td>\n","      <td>54.0</td>\n","      <td>0.9970</td>\n","      <td>3.26</td>\n","      <td>0.65</td>\n","      <td>9.8</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.2</td>\n","      <td>0.28</td>\n","      <td>0.56</td>\n","      <td>1.9</td>\n","      <td>0.075</td>\n","      <td>17.0</td>\n","      <td>60.0</td>\n","      <td>0.9980</td>\n","      <td>3.16</td>\n","      <td>0.58</td>\n","      <td>9.8</td>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7.4</td>\n","      <td>0.70</td>\n","      <td>0.00</td>\n","      <td>1.9</td>\n","      <td>0.076</td>\n","      <td>11.0</td>\n","      <td>34.0</td>\n","      <td>0.9978</td>\n","      <td>3.51</td>\n","      <td>0.56</td>\n","      <td>9.4</td>\n","      <td>5</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   fixed_acidity  volatile_acidity  citric_acid  ...  alcohol  quality  color\n","0            7.4              0.70         0.00  ...      9.4        5      0\n","1            7.8              0.88         0.00  ...      9.8        5      0\n","2            7.8              0.76         0.04  ...      9.8        5      0\n","3           11.2              0.28         0.56  ...      9.8        6      0\n","4            7.4              0.70         0.00  ...      9.4        5      0\n","\n","[5 rows x 13 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"CqVRVxFEaWhU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597023721764,"user_tz":-330,"elapsed":5361,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"ad6dbc4e-3fd6-4e4e-c19d-3b53a0d39aff"},"source":["encoder.classes_"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['red', 'white'], dtype=object)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"W0lBXi3rcftL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597023721764,"user_tz":-330,"elapsed":5352,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"322a7afb-d8bd-4f2a-b443-d940353bb7a4"},"source":["df.color.unique()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"QENtFEPjoWaj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1597023721765,"user_tz":-330,"elapsed":5344,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"6ef3143c-225c-4c58-a717-b96ec68d4ed5"},"source":["df.color.value_counts()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1    4898\n","0    1599\n","Name: color, dtype: int64"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"IIsaiLdycnFE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721766,"user_tz":-330,"elapsed":5339,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["# create feature and target labels"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"EsiWAJ6Pc2wP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721767,"user_tz":-330,"elapsed":5334,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["X= df.iloc[:,:12].values\n","y = df.iloc[:,12].values"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UyPuxWUc_m0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"status":"ok","timestamp":1597023721767,"user_tz":-330,"elapsed":5320,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"23115b2d-1a42-4d95-fa1e-c1409fc14422"},"source":["X"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 7.4 ,  0.7 ,  0.  , ...,  0.56,  9.4 ,  5.  ],\n","       [ 7.8 ,  0.88,  0.  , ...,  0.68,  9.8 ,  5.  ],\n","       [ 7.8 ,  0.76,  0.04, ...,  0.65,  9.8 ,  5.  ],\n","       ...,\n","       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n","       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n","       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"ejabguQBd8zX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721767,"user_tz":-330,"elapsed":5312,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"LO1kBLITdAcM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721768,"user_tz":-330,"elapsed":5309,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["from sklearn.linear_model import LogisticRegression"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"1st1bbmyd33X","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":183},"executionInfo":{"status":"ok","timestamp":1597023721768,"user_tz":-330,"elapsed":5301,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"172fd941-0c8a-41d5-d4c5-66e06a0ea163"},"source":["lr = LogisticRegression()\n","lr.fit(X_train,y_train)\n","lr.score(X_test,y_test)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.9730769230769231"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"WW9pP0NeeOa3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721768,"user_tz":-330,"elapsed":5295,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["from sklearn.preprocessing import MinMaxScaler\n","scale = MinMaxScaler()"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"WiA92o-LeuM0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721770,"user_tz":-330,"elapsed":5293,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["X_strain = scale.fit_transform(X_train)\n","X_stest = scale.transform(X_test)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mw676OzYe-qd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597023721770,"user_tz":-330,"elapsed":5285,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"beda7ec0-026b-4691-e583-9be3652c10c8"},"source":["lr.fit(X_strain,y_train)\n","lr.score(X_stest,y_test)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9830769230769231"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"f32mL5ZOiOjs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1597023721771,"user_tz":-330,"elapsed":5278,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"a69c95c9-aa97-4214-dc05-cf4c086b36e2"},"source":["lr.get_params"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"YsF9w47jfJOz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721771,"user_tz":-330,"elapsed":5271,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["# WE CHECK THE CONFUSION MATRIX"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"3U215lFjfYOt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721772,"user_tz":-330,"elapsed":5267,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["from sklearn.metrics import classification_report,confusion_matrix"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wi1h8EGOfmLT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1597023721772,"user_tz":-330,"elapsed":5262,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"e9779da4-19fa-4f67-eedd-501fd687739f"},"source":["y_pred = lr.predict(X_stest)\n","print(confusion_matrix(y_test,y_pred))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[[323  18]\n"," [  4 955]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PlnDo330f5PU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1597023721772,"user_tz":-330,"elapsed":5254,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"7f841293-a683-4605-93cd-4416437929e5"},"source":["classification_report(y_test,y_pred)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'              precision    recall  f1-score   support\\n\\n           0       0.99      0.95      0.97       341\\n           1       0.98      1.00      0.99       959\\n\\n    accuracy                           0.98      1300\\n   macro avg       0.98      0.97      0.98      1300\\nweighted avg       0.98      0.98      0.98      1300\\n'"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"Xj9DopiKgYcs","colab_type":"text"},"source":["              precision    recall  f1-score   support\n","\n","           0       0.99      0.95      0.97       341\n","           1       0.98      1.00      0.99       959\n","\n","     accuracy                          0.98      1300\n","    macro avg      0.98      0.97      0.98      1300\n","    weighted avg   0.98      0.98      0.98      1300\n"]},{"cell_type":"code","metadata":{"id":"goIY2LJugODF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023721773,"user_tz":-330,"elapsed":5249,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["# this data come without hyperparameter tuning"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"QplLIkbAgqVE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597023756530,"user_tz":-330,"elapsed":1223,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"9107038c-b8e9-477c-e69a-27a22565918e"},"source":["lr= LogisticRegression(penalty='l2',C=10)\n","lr.fit(X_strain,y_train)\n","lr.score(X_stest,y_test)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9853846153846154"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"MNTbjofCiFkj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023756952,"user_tz":-330,"elapsed":790,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["from sklearn.model_selection import GridSearchCV"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"HOf9z4KajFbU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023758489,"user_tz":-330,"elapsed":877,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["penalty = ['l1','l2']\n","C = np.logspace(-4,4,20)\n","solver = ['liblinear','sag','lbfgs']\n","\n","parameter ={\n","    'penalty':penalty,\n","    'C':C,\n","    'solver':solver\n","}\n","lr = LogisticRegression(random_state=42)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0nD4QoxjGUQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023761603,"user_tz":-330,"elapsed":1076,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["grid_search = GridSearchCV(lr,param_grid=parameter,cv=3,verbose=3,)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"I_4xNzK2jGXG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597023773725,"user_tz":-330,"elapsed":12213,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"d7bc5e36-a3f6-4951-943a-633575eb851b"},"source":["grid_search.fit(X_strain,y_train)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Fitting 3 folds for each of 120 candidates, totalling 360 fits\n","[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n","[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n","[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=liblinear ..........................\n","[CV]  C=0.0001, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=sag ................................\n","[CV] ...... C=0.0001, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=sag ................................\n","[CV] ...... C=0.0001, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=sag ................................\n","[CV] ...... C=0.0001, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n","[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n","[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0001, penalty=l1, solver=lbfgs ..............................\n","[CV] .... C=0.0001, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n","[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n","[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=liblinear ..........................\n","[CV]  C=0.0001, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=sag ................................\n","[CV] .... C=0.0001, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=sag ................................\n","[CV] .... C=0.0001, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=sag ................................\n","[CV] .... C=0.0001, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n","[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n","[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0001, penalty=l2, solver=lbfgs ..............................\n","[CV] .. C=0.0001, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=liblinear ..........\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=liblinear ..........\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=liblinear ..........\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=sag ................\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=sag ................\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=sag ................\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=lbfgs ..............\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=lbfgs ..............\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l1, solver=lbfgs ..............\n","[CV]  C=0.00026366508987303583, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=liblinear ..........\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=liblinear ..........\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=liblinear ..........\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n","[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n","[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=0.00026366508987303583, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=sag ................\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=sag ................\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=sag ................\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=lbfgs ..............\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=lbfgs ..............\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.00026366508987303583, penalty=l2, solver=lbfgs ..............\n","[CV]  C=0.00026366508987303583, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=liblinear ...........\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=liblinear ...........\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=liblinear ...........\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=liblinear, score=0.242, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=sag .................\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=sag .................\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=sag .................\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=lbfgs ...............\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=lbfgs ...............\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l1, solver=lbfgs ...............\n","[CV]  C=0.0006951927961775605, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=liblinear ...........\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=liblinear ...........\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=liblinear ...........\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=sag .................\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=sag .................\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=sag .................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=0.0006951927961775605, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=lbfgs ...............\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=lbfgs ...............\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0006951927961775605, penalty=l2, solver=lbfgs ...............\n","[CV]  C=0.0006951927961775605, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=liblinear ...........\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=liblinear ...........\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=liblinear ...........\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=sag .................\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=sag .................\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=sag .................\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=lbfgs ...............\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=lbfgs ...............\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l1, solver=lbfgs ...............\n","[CV]  C=0.0018329807108324356, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=liblinear ...........\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=liblinear ...........\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=liblinear ...........\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=sag .................\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=sag .................\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=sag .................\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=lbfgs ...............\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=lbfgs ...............\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.0018329807108324356, penalty=l2, solver=lbfgs ...............\n","[CV]  C=0.0018329807108324356, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=liblinear ............\n","[CV]  C=0.004832930238571752, penalty=l1, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=liblinear ............\n","[CV]  C=0.004832930238571752, penalty=l1, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=liblinear ............\n","[CV]  C=0.004832930238571752, penalty=l1, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=sag ..................\n","[CV]  C=0.004832930238571752, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=sag ..................\n","[CV]  C=0.004832930238571752, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=sag ..................\n","[CV]  C=0.004832930238571752, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=lbfgs ................\n","[CV]  C=0.004832930238571752, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=lbfgs ................\n","[CV]  C=0.004832930238571752, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l1, solver=lbfgs ................\n","[CV]  C=0.004832930238571752, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=liblinear ............\n","[CV]  C=0.004832930238571752, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=liblinear ............\n","[CV]  C=0.004832930238571752, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=liblinear ............\n","[CV]  C=0.004832930238571752, penalty=l2, solver=liblinear, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=sag ..................\n","[CV]  C=0.004832930238571752, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=sag ..................\n","[CV]  C=0.004832930238571752, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=sag ..................\n","[CV]  C=0.004832930238571752, penalty=l2, solver=sag, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=lbfgs ................\n","[CV]  C=0.004832930238571752, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=lbfgs ................\n","[CV]  C=0.004832930238571752, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.004832930238571752, penalty=l2, solver=lbfgs ................\n","[CV]  C=0.004832930238571752, penalty=l2, solver=lbfgs, score=0.758, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=liblinear ............\n","[CV]  C=0.012742749857031334, penalty=l1, solver=liblinear, score=0.845, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=liblinear ............\n","[CV]  C=0.012742749857031334, penalty=l1, solver=liblinear, score=0.848, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=liblinear ............\n","[CV]  C=0.012742749857031334, penalty=l1, solver=liblinear, score=0.841, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=sag ..................\n","[CV]  C=0.012742749857031334, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=sag ..................\n","[CV]  C=0.012742749857031334, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=sag ..................\n","[CV]  C=0.012742749857031334, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=lbfgs ................\n","[CV]  C=0.012742749857031334, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=lbfgs ................\n","[CV]  C=0.012742749857031334, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l1, solver=lbfgs ................\n","[CV]  C=0.012742749857031334, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=liblinear ............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=0.012742749857031334, penalty=l2, solver=liblinear, score=0.774, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=liblinear ............\n","[CV]  C=0.012742749857031334, penalty=l2, solver=liblinear, score=0.770, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=liblinear ............\n","[CV]  C=0.012742749857031334, penalty=l2, solver=liblinear, score=0.779, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=sag ..................\n","[CV]  C=0.012742749857031334, penalty=l2, solver=sag, score=0.766, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=sag ..................\n","[CV]  C=0.012742749857031334, penalty=l2, solver=sag, score=0.761, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=sag ..................\n","[CV]  C=0.012742749857031334, penalty=l2, solver=sag, score=0.767, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=lbfgs ................\n","[CV]  C=0.012742749857031334, penalty=l2, solver=lbfgs, score=0.766, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=lbfgs ................\n","[CV]  C=0.012742749857031334, penalty=l2, solver=lbfgs, score=0.761, total=   0.0s\n","[CV] C=0.012742749857031334, penalty=l2, solver=lbfgs ................\n","[CV]  C=0.012742749857031334, penalty=l2, solver=lbfgs, score=0.767, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=liblinear .............\n","[CV]  C=0.03359818286283781, penalty=l1, solver=liblinear, score=0.949, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=liblinear .............\n","[CV]  C=0.03359818286283781, penalty=l1, solver=liblinear, score=0.958, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=liblinear .............\n","[CV]  C=0.03359818286283781, penalty=l1, solver=liblinear, score=0.943, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=sag ...................\n","[CV]  C=0.03359818286283781, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=sag ...................\n","[CV]  C=0.03359818286283781, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=sag ...................\n","[CV]  C=0.03359818286283781, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.03359818286283781, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.03359818286283781, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.03359818286283781, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=liblinear .............\n","[CV]  C=0.03359818286283781, penalty=l2, solver=liblinear, score=0.907, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=liblinear .............\n","[CV]  C=0.03359818286283781, penalty=l2, solver=liblinear, score=0.913, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=liblinear .............\n","[CV]  C=0.03359818286283781, penalty=l2, solver=liblinear, score=0.911, total=   0.0s"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\n","[CV] C=0.03359818286283781, penalty=l2, solver=sag ...................\n","[CV]  C=0.03359818286283781, penalty=l2, solver=sag, score=0.900, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=sag ...................\n","[CV]  C=0.03359818286283781, penalty=l2, solver=sag, score=0.905, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=sag ...................\n","[CV]  C=0.03359818286283781, penalty=l2, solver=sag, score=0.907, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.03359818286283781, penalty=l2, solver=lbfgs, score=0.900, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.03359818286283781, penalty=l2, solver=lbfgs, score=0.905, total=   0.0s\n","[CV] C=0.03359818286283781, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.03359818286283781, penalty=l2, solver=lbfgs, score=0.907, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=liblinear .............\n","[CV]  C=0.08858667904100823, penalty=l1, solver=liblinear, score=0.973, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=liblinear .............\n","[CV]  C=0.08858667904100823, penalty=l1, solver=liblinear, score=0.974, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=liblinear .............\n","[CV]  C=0.08858667904100823, penalty=l1, solver=liblinear, score=0.963, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=sag ...................\n","[CV]  C=0.08858667904100823, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=sag ...................\n","[CV]  C=0.08858667904100823, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=sag ...................\n","[CV]  C=0.08858667904100823, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.08858667904100823, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.08858667904100823, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.08858667904100823, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=liblinear .............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=0.08858667904100823, penalty=l2, solver=liblinear, score=0.963, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=liblinear .............\n","[CV]  C=0.08858667904100823, penalty=l2, solver=liblinear, score=0.969, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=liblinear .............\n","[CV]  C=0.08858667904100823, penalty=l2, solver=liblinear, score=0.958, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=sag ...................\n","[CV]  C=0.08858667904100823, penalty=l2, solver=sag, score=0.960, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=sag ...................\n","[CV]  C=0.08858667904100823, penalty=l2, solver=sag, score=0.971, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=sag ...................\n","[CV]  C=0.08858667904100823, penalty=l2, solver=sag, score=0.959, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.08858667904100823, penalty=l2, solver=lbfgs, score=0.960, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.08858667904100823, penalty=l2, solver=lbfgs, score=0.971, total=   0.0s\n","[CV] C=0.08858667904100823, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.08858667904100823, penalty=l2, solver=lbfgs, score=0.959, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l1, solver=liblinear .............\n","[CV]  C=0.23357214690901212, penalty=l1, solver=liblinear, score=0.983, total=   0.1s\n","[CV] C=0.23357214690901212, penalty=l1, solver=liblinear .............\n","[CV]  C=0.23357214690901212, penalty=l1, solver=liblinear, score=0.986, total=   0.1s\n","[CV] C=0.23357214690901212, penalty=l1, solver=liblinear .............\n","[CV]  C=0.23357214690901212, penalty=l1, solver=liblinear, score=0.976, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l1, solver=sag ...................\n","[CV]  C=0.23357214690901212, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l1, solver=sag ...................\n","[CV]  C=0.23357214690901212, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l1, solver=sag ...................\n","[CV]  C=0.23357214690901212, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.23357214690901212, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.23357214690901212, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l1, solver=lbfgs .................\n","[CV]  C=0.23357214690901212, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=liblinear .............\n","[CV]  C=0.23357214690901212, penalty=l2, solver=liblinear, score=0.977, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=liblinear .............\n","[CV]  C=0.23357214690901212, penalty=l2, solver=liblinear, score=0.982, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=liblinear .............\n","[CV]  C=0.23357214690901212, penalty=l2, solver=liblinear, score=0.972, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=sag ...................\n","[CV]  C=0.23357214690901212, penalty=l2, solver=sag, score=0.977, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=sag ...................\n","[CV]  C=0.23357214690901212, penalty=l2, solver=sag, score=0.986, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=sag ...................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=0.23357214690901212, penalty=l2, solver=sag, score=0.974, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.23357214690901212, penalty=l2, solver=lbfgs, score=0.977, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.23357214690901212, penalty=l2, solver=lbfgs, score=0.986, total=   0.0s\n","[CV] C=0.23357214690901212, penalty=l2, solver=lbfgs .................\n","[CV]  C=0.23357214690901212, penalty=l2, solver=lbfgs, score=0.974, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l1, solver=liblinear ...............\n","[CV]  C=0.615848211066026, penalty=l1, solver=liblinear, score=0.987, total=   0.1s\n","[CV] C=0.615848211066026, penalty=l1, solver=liblinear ...............\n","[CV]  C=0.615848211066026, penalty=l1, solver=liblinear, score=0.991, total=   0.1s\n","[CV] C=0.615848211066026, penalty=l1, solver=liblinear ...............\n","[CV]  C=0.615848211066026, penalty=l1, solver=liblinear, score=0.986, total=   0.1s\n","[CV] C=0.615848211066026, penalty=l1, solver=sag .....................\n","[CV]  C=0.615848211066026, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l1, solver=sag .....................\n","[CV]  C=0.615848211066026, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l1, solver=sag .....................\n","[CV]  C=0.615848211066026, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l1, solver=lbfgs ...................\n","[CV]  C=0.615848211066026, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l1, solver=lbfgs ...................\n","[CV]  C=0.615848211066026, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l1, solver=lbfgs ...................\n","[CV]  C=0.615848211066026, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=liblinear ...............\n","[CV]  C=0.615848211066026, penalty=l2, solver=liblinear, score=0.984, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=liblinear ...............\n","[CV]  C=0.615848211066026, penalty=l2, solver=liblinear, score=0.987, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=liblinear ...............\n","[CV]  C=0.615848211066026, penalty=l2, solver=liblinear, score=0.977, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=sag .....................\n","[CV]  C=0.615848211066026, penalty=l2, solver=sag, score=0.986, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=sag .....................\n","[CV]  C=0.615848211066026, penalty=l2, solver=sag, score=0.990, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=sag .....................\n","[CV]  C=0.615848211066026, penalty=l2, solver=sag, score=0.979, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=lbfgs ...................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=0.615848211066026, penalty=l2, solver=lbfgs, score=0.986, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=lbfgs ...................\n","[CV]  C=0.615848211066026, penalty=l2, solver=lbfgs, score=0.990, total=   0.0s\n","[CV] C=0.615848211066026, penalty=l2, solver=lbfgs ...................\n","[CV]  C=0.615848211066026, penalty=l2, solver=lbfgs, score=0.979, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l1, solver=liblinear ...............\n","[CV]  C=1.623776739188721, penalty=l1, solver=liblinear, score=0.990, total=   0.1s\n","[CV] C=1.623776739188721, penalty=l1, solver=liblinear ...............\n","[CV]  C=1.623776739188721, penalty=l1, solver=liblinear, score=0.994, total=   0.1s\n","[CV] C=1.623776739188721, penalty=l1, solver=liblinear ...............\n","[CV]  C=1.623776739188721, penalty=l1, solver=liblinear, score=0.991, total=   0.1s\n","[CV] C=1.623776739188721, penalty=l1, solver=sag .....................\n","[CV]  C=1.623776739188721, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l1, solver=sag .....................\n","[CV]  C=1.623776739188721, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l1, solver=sag .....................\n","[CV]  C=1.623776739188721, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l1, solver=lbfgs ...................\n","[CV]  C=1.623776739188721, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l1, solver=lbfgs ...................\n","[CV]  C=1.623776739188721, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l1, solver=lbfgs ...................\n","[CV]  C=1.623776739188721, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=liblinear ...............\n","[CV]  C=1.623776739188721, penalty=l2, solver=liblinear, score=0.988, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=liblinear ...............\n","[CV]  C=1.623776739188721, penalty=l2, solver=liblinear, score=0.992, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=liblinear ...............\n","[CV]  C=1.623776739188721, penalty=l2, solver=liblinear, score=0.982, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=sag .....................\n","[CV]  C=1.623776739188721, penalty=l2, solver=sag, score=0.987, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=sag .....................\n","[CV]  C=1.623776739188721, penalty=l2, solver=sag, score=0.991, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=sag .....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=1.623776739188721, penalty=l2, solver=sag, score=0.983, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=lbfgs ...................\n","[CV]  C=1.623776739188721, penalty=l2, solver=lbfgs, score=0.987, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=lbfgs ...................\n","[CV]  C=1.623776739188721, penalty=l2, solver=lbfgs, score=0.991, total=   0.0s\n","[CV] C=1.623776739188721, penalty=l2, solver=lbfgs ...................\n","[CV]  C=1.623776739188721, penalty=l2, solver=lbfgs, score=0.983, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l1, solver=liblinear ...............\n","[CV]  C=4.281332398719396, penalty=l1, solver=liblinear, score=0.992, total=   0.1s\n","[CV] C=4.281332398719396, penalty=l1, solver=liblinear ...............\n","[CV]  C=4.281332398719396, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=4.281332398719396, penalty=l1, solver=liblinear ...............\n","[CV]  C=4.281332398719396, penalty=l1, solver=liblinear, score=0.994, total=   0.1s\n","[CV] C=4.281332398719396, penalty=l1, solver=sag .....................\n","[CV]  C=4.281332398719396, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l1, solver=sag .....................\n","[CV]  C=4.281332398719396, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l1, solver=sag .....................\n","[CV]  C=4.281332398719396, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l1, solver=lbfgs ...................\n","[CV]  C=4.281332398719396, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l1, solver=lbfgs ...................\n","[CV]  C=4.281332398719396, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l1, solver=lbfgs ...................\n","[CV]  C=4.281332398719396, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=liblinear ...............\n","[CV]  C=4.281332398719396, penalty=l2, solver=liblinear, score=0.988, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=liblinear ...............\n","[CV]  C=4.281332398719396, penalty=l2, solver=liblinear, score=0.992, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=liblinear ...............\n","[CV]  C=4.281332398719396, penalty=l2, solver=liblinear, score=0.986, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=sag .....................\n","[CV]  C=4.281332398719396, penalty=l2, solver=sag, score=0.989, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=sag .....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=4.281332398719396, penalty=l2, solver=sag, score=0.992, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=sag .....................\n","[CV]  C=4.281332398719396, penalty=l2, solver=sag, score=0.987, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=lbfgs ...................\n","[CV]  C=4.281332398719396, penalty=l2, solver=lbfgs, score=0.989, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=lbfgs ...................\n","[CV]  C=4.281332398719396, penalty=l2, solver=lbfgs, score=0.992, total=   0.0s\n","[CV] C=4.281332398719396, penalty=l2, solver=lbfgs ...................\n","[CV]  C=4.281332398719396, penalty=l2, solver=lbfgs, score=0.987, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l1, solver=liblinear ..............\n","[CV]  C=11.288378916846883, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=11.288378916846883, penalty=l1, solver=liblinear ..............\n","[CV]  C=11.288378916846883, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=11.288378916846883, penalty=l1, solver=liblinear ..............\n","[CV]  C=11.288378916846883, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=11.288378916846883, penalty=l1, solver=sag ....................\n","[CV]  C=11.288378916846883, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l1, solver=sag ....................\n","[CV]  C=11.288378916846883, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l1, solver=sag ....................\n","[CV]  C=11.288378916846883, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l1, solver=lbfgs ..................\n","[CV]  C=11.288378916846883, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l1, solver=lbfgs ..................\n","[CV]  C=11.288378916846883, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l1, solver=lbfgs ..................\n","[CV]  C=11.288378916846883, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l2, solver=liblinear ..............\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=11.288378916846883, penalty=l2, solver=liblinear, score=0.990, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l2, solver=liblinear ..............\n","[CV]  C=11.288378916846883, penalty=l2, solver=liblinear, score=0.993, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l2, solver=liblinear ..............\n","[CV]  C=11.288378916846883, penalty=l2, solver=liblinear, score=0.989, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l2, solver=sag ....................\n","[CV]  C=11.288378916846883, penalty=l2, solver=sag, score=0.990, total=   0.1s\n","[CV] C=11.288378916846883, penalty=l2, solver=sag ....................\n","[CV]  C=11.288378916846883, penalty=l2, solver=sag, score=0.993, total=   0.1s\n","[CV] C=11.288378916846883, penalty=l2, solver=sag ....................\n","[CV]  C=11.288378916846883, penalty=l2, solver=sag, score=0.990, total=   0.1s\n","[CV] C=11.288378916846883, penalty=l2, solver=lbfgs ..................\n","[CV]  C=11.288378916846883, penalty=l2, solver=lbfgs, score=0.990, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l2, solver=lbfgs ..................\n","[CV]  C=11.288378916846883, penalty=l2, solver=lbfgs, score=0.993, total=   0.0s\n","[CV] C=11.288378916846883, penalty=l2, solver=lbfgs ..................\n","[CV]  C=11.288378916846883, penalty=l2, solver=lbfgs, score=0.990, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l1, solver=liblinear ..............\n","[CV]  C=29.763514416313132, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l1, solver=liblinear ..............\n","[CV]  C=29.763514416313132, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l1, solver=liblinear ..............\n","[CV]  C=29.763514416313132, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l1, solver=sag ....................\n","[CV]  C=29.763514416313132, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l1, solver=sag ....................\n","[CV]  C=29.763514416313132, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l1, solver=sag ....................\n","[CV]  C=29.763514416313132, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l1, solver=lbfgs ..................\n","[CV]  C=29.763514416313132, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l1, solver=lbfgs ..................\n","[CV]  C=29.763514416313132, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l1, solver=lbfgs ..................\n","[CV]  C=29.763514416313132, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l2, solver=liblinear ..............\n","[CV]  C=29.763514416313132, penalty=l2, solver=liblinear, score=0.990, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l2, solver=liblinear ..............\n","[CV]  C=29.763514416313132, penalty=l2, solver=liblinear, score=0.994, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l2, solver=liblinear ..............\n","[CV]  C=29.763514416313132, penalty=l2, solver=liblinear, score=0.990, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l2, solver=sag ....................\n","[CV]  C=29.763514416313132, penalty=l2, solver=sag, score=0.990, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l2, solver=sag ....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=29.763514416313132, penalty=l2, solver=sag, score=0.994, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l2, solver=sag ....................\n","[CV]  C=29.763514416313132, penalty=l2, solver=sag, score=0.991, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l2, solver=lbfgs ..................\n","[CV]  C=29.763514416313132, penalty=l2, solver=lbfgs, score=0.990, total=   0.0s\n","[CV] C=29.763514416313132, penalty=l2, solver=lbfgs ..................\n","[CV]  C=29.763514416313132, penalty=l2, solver=lbfgs, score=0.994, total=   0.1s\n","[CV] C=29.763514416313132, penalty=l2, solver=lbfgs ..................\n","[CV]  C=29.763514416313132, penalty=l2, solver=lbfgs, score=0.991, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l1, solver=liblinear ...............\n","[CV]  C=78.47599703514607, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l1, solver=liblinear ...............\n","[CV]  C=78.47599703514607, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l1, solver=liblinear ...............\n","[CV]  C=78.47599703514607, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l1, solver=sag .....................\n","[CV]  C=78.47599703514607, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l1, solver=sag .....................\n","[CV]  C=78.47599703514607, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l1, solver=sag .....................\n","[CV]  C=78.47599703514607, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l1, solver=lbfgs ...................\n","[CV]  C=78.47599703514607, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l1, solver=lbfgs ...................\n","[CV]  C=78.47599703514607, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l1, solver=lbfgs ...................\n","[CV]  C=78.47599703514607, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l2, solver=liblinear ...............\n","[CV]  C=78.47599703514607, penalty=l2, solver=liblinear, score=0.991, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l2, solver=liblinear ...............\n","[CV]  C=78.47599703514607, penalty=l2, solver=liblinear, score=0.994, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l2, solver=liblinear ...............\n","[CV]  C=78.47599703514607, penalty=l2, solver=liblinear, score=0.992, total=   0.0s\n","[CV] C=78.47599703514607, penalty=l2, solver=sag .....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=78.47599703514607, penalty=l2, solver=sag, score=0.990, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l2, solver=sag .....................\n","[CV]  C=78.47599703514607, penalty=l2, solver=sag, score=0.994, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l2, solver=sag .....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=78.47599703514607, penalty=l2, solver=sag, score=0.991, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l2, solver=lbfgs ...................\n","[CV]  C=78.47599703514607, penalty=l2, solver=lbfgs, score=0.991, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l2, solver=lbfgs ...................\n","[CV]  C=78.47599703514607, penalty=l2, solver=lbfgs, score=0.994, total=   0.1s\n","[CV] C=78.47599703514607, penalty=l2, solver=lbfgs ...................\n","[CV]  C=78.47599703514607, penalty=l2, solver=lbfgs, score=0.991, total=   0.1s\n","[CV] C=206.913808111479, penalty=l1, solver=liblinear ................\n","[CV]  C=206.913808111479, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=206.913808111479, penalty=l1, solver=liblinear ................\n","[CV]  C=206.913808111479, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=206.913808111479, penalty=l1, solver=liblinear ................\n","[CV]  C=206.913808111479, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=206.913808111479, penalty=l1, solver=sag ......................\n","[CV]  C=206.913808111479, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=206.913808111479, penalty=l1, solver=sag ......................\n","[CV]  C=206.913808111479, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=206.913808111479, penalty=l1, solver=sag ......................\n","[CV]  C=206.913808111479, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=206.913808111479, penalty=l1, solver=lbfgs ....................\n","[CV]  C=206.913808111479, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=206.913808111479, penalty=l1, solver=lbfgs ....................\n","[CV]  C=206.913808111479, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=206.913808111479, penalty=l1, solver=lbfgs ....................\n","[CV]  C=206.913808111479, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=206.913808111479, penalty=l2, solver=liblinear ................\n","[CV]  C=206.913808111479, penalty=l2, solver=liblinear, score=0.992, total=   0.0s\n","[CV] C=206.913808111479, penalty=l2, solver=liblinear ................\n","[CV]  C=206.913808111479, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=206.913808111479, penalty=l2, solver=liblinear ................\n","[CV]  C=206.913808111479, penalty=l2, solver=liblinear, score=0.994, total=   0.0s\n","[CV] C=206.913808111479, penalty=l2, solver=sag ......................\n","[CV]  C=206.913808111479, penalty=l2, solver=sag, score=0.991, total=   0.1s\n","[CV] C=206.913808111479, penalty=l2, solver=sag ......................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=206.913808111479, penalty=l2, solver=sag, score=0.994, total=   0.1s\n","[CV] C=206.913808111479, penalty=l2, solver=sag ......................\n","[CV]  C=206.913808111479, penalty=l2, solver=sag, score=0.992, total=   0.1s\n","[CV] C=206.913808111479, penalty=l2, solver=lbfgs ....................\n","[CV]  C=206.913808111479, penalty=l2, solver=lbfgs, score=0.992, total=   0.1s\n","[CV] C=206.913808111479, penalty=l2, solver=lbfgs ....................\n","[CV]  C=206.913808111479, penalty=l2, solver=lbfgs, score=0.995, total=   0.0s\n","[CV] C=206.913808111479, penalty=l2, solver=lbfgs ....................\n","[CV]  C=206.913808111479, penalty=l2, solver=lbfgs, score=0.994, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l1, solver=liblinear ...............\n","[CV]  C=545.5594781168514, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l1, solver=liblinear ...............\n","[CV]  C=545.5594781168514, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l1, solver=liblinear ...............\n","[CV]  C=545.5594781168514, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l1, solver=sag .....................\n","[CV]  C=545.5594781168514, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l1, solver=sag .....................\n","[CV]  C=545.5594781168514, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l1, solver=sag .....................\n","[CV]  C=545.5594781168514, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l1, solver=lbfgs ...................\n","[CV]  C=545.5594781168514, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l1, solver=lbfgs ...................\n","[CV]  C=545.5594781168514, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l1, solver=lbfgs ...................\n","[CV]  C=545.5594781168514, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l2, solver=liblinear ...............\n","[CV]  C=545.5594781168514, penalty=l2, solver=liblinear, score=0.992, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l2, solver=liblinear ...............\n","[CV]  C=545.5594781168514, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l2, solver=liblinear ...............\n","[CV]  C=545.5594781168514, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=545.5594781168514, penalty=l2, solver=sag .....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=545.5594781168514, penalty=l2, solver=sag, score=0.991, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l2, solver=sag .....................\n","[CV]  C=545.5594781168514, penalty=l2, solver=sag, score=0.994, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l2, solver=sag .....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=545.5594781168514, penalty=l2, solver=sag, score=0.992, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l2, solver=lbfgs ...................\n","[CV]  C=545.5594781168514, penalty=l2, solver=lbfgs, score=0.992, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l2, solver=lbfgs ...................\n","[CV]  C=545.5594781168514, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n","[CV] C=545.5594781168514, penalty=l2, solver=lbfgs ...................\n","[CV]  C=545.5594781168514, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l1, solver=liblinear ................\n","[CV]  C=1438.44988828766, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l1, solver=liblinear ................\n","[CV]  C=1438.44988828766, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l1, solver=liblinear ................\n","[CV]  C=1438.44988828766, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l1, solver=sag ......................\n","[CV]  C=1438.44988828766, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l1, solver=sag ......................\n","[CV]  C=1438.44988828766, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l1, solver=sag ......................\n","[CV]  C=1438.44988828766, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l1, solver=lbfgs ....................\n","[CV]  C=1438.44988828766, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l1, solver=lbfgs ....................\n","[CV]  C=1438.44988828766, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l1, solver=lbfgs ....................\n","[CV]  C=1438.44988828766, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l2, solver=liblinear ................\n","[CV]  C=1438.44988828766, penalty=l2, solver=liblinear, score=0.993, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l2, solver=liblinear ................\n","[CV]  C=1438.44988828766, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l2, solver=liblinear ................\n","[CV]  C=1438.44988828766, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=1438.44988828766, penalty=l2, solver=sag ......................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=1438.44988828766, penalty=l2, solver=sag, score=0.991, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l2, solver=sag ......................\n","[CV]  C=1438.44988828766, penalty=l2, solver=sag, score=0.994, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l2, solver=sag ......................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=1438.44988828766, penalty=l2, solver=sag, score=0.992, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l2, solver=lbfgs ....................\n","[CV]  C=1438.44988828766, penalty=l2, solver=lbfgs, score=0.993, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l2, solver=lbfgs ....................\n","[CV]  C=1438.44988828766, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n","[CV] C=1438.44988828766, penalty=l2, solver=lbfgs ....................\n","[CV]  C=1438.44988828766, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l1, solver=liblinear ...............\n","[CV]  C=3792.690190732246, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l1, solver=liblinear ...............\n","[CV]  C=3792.690190732246, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l1, solver=liblinear ...............\n","[CV]  C=3792.690190732246, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l1, solver=sag .....................\n","[CV]  C=3792.690190732246, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l1, solver=sag .....................\n","[CV]  C=3792.690190732246, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l1, solver=sag .....................\n","[CV]  C=3792.690190732246, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l1, solver=lbfgs ...................\n","[CV]  C=3792.690190732246, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l1, solver=lbfgs ...................\n","[CV]  C=3792.690190732246, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l1, solver=lbfgs ...................\n","[CV]  C=3792.690190732246, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l2, solver=liblinear ...............\n","[CV]  C=3792.690190732246, penalty=l2, solver=liblinear, score=0.993, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l2, solver=liblinear ...............\n","[CV]  C=3792.690190732246, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l2, solver=liblinear ...............\n","[CV]  C=3792.690190732246, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=3792.690190732246, penalty=l2, solver=sag .....................\n","[CV]  C=3792.690190732246, penalty=l2, solver=sag, score=0.991, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l2, solver=sag .....................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=3792.690190732246, penalty=l2, solver=sag, score=0.994, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l2, solver=sag .....................\n","[CV]  C=3792.690190732246, penalty=l2, solver=sag, score=0.992, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l2, solver=lbfgs ...................\n","[CV]  C=3792.690190732246, penalty=l2, solver=lbfgs, score=0.993, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l2, solver=lbfgs ...................\n","[CV]  C=3792.690190732246, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n","[CV] C=3792.690190732246, penalty=l2, solver=lbfgs ...................\n","[CV]  C=3792.690190732246, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n","[CV] C=10000.0, penalty=l1, solver=liblinear .........................\n","[CV]  C=10000.0, penalty=l1, solver=liblinear, score=0.993, total=   0.1s\n","[CV] C=10000.0, penalty=l1, solver=liblinear .........................\n","[CV]  C=10000.0, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=10000.0, penalty=l1, solver=liblinear .........................\n","[CV]  C=10000.0, penalty=l1, solver=liblinear, score=0.995, total=   0.1s\n","[CV] C=10000.0, penalty=l1, solver=sag ...............................\n","[CV] ..... C=10000.0, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=10000.0, penalty=l1, solver=sag ...............................\n","[CV] ..... C=10000.0, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=10000.0, penalty=l1, solver=sag ...............................\n","[CV] ..... C=10000.0, penalty=l1, solver=sag, score=nan, total=   0.0s\n","[CV] C=10000.0, penalty=l1, solver=lbfgs .............................\n","[CV] ... C=10000.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=10000.0, penalty=l1, solver=lbfgs .............................\n","[CV] ... C=10000.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=10000.0, penalty=l1, solver=lbfgs .............................\n","[CV] ... C=10000.0, penalty=l1, solver=lbfgs, score=nan, total=   0.0s\n","[CV] C=10000.0, penalty=l2, solver=liblinear .........................\n","[CV]  C=10000.0, penalty=l2, solver=liblinear, score=0.993, total=   0.0s\n","[CV] C=10000.0, penalty=l2, solver=liblinear .........................\n","[CV]  C=10000.0, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=10000.0, penalty=l2, solver=liblinear .........................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n","ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n","\n","  FitFailedWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV]  C=10000.0, penalty=l2, solver=liblinear, score=0.995, total=   0.0s\n","[CV] C=10000.0, penalty=l2, solver=sag ...............................\n","[CV] ... C=10000.0, penalty=l2, solver=sag, score=0.991, total=   0.1s\n","[CV] C=10000.0, penalty=l2, solver=sag ...............................\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  \"the coef_ did not converge\", ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[CV] ... C=10000.0, penalty=l2, solver=sag, score=0.994, total=   0.1s\n","[CV] C=10000.0, penalty=l2, solver=sag ...............................\n","[CV] ... C=10000.0, penalty=l2, solver=sag, score=0.992, total=   0.1s\n","[CV] C=10000.0, penalty=l2, solver=lbfgs .............................\n","[CV] . C=10000.0, penalty=l2, solver=lbfgs, score=0.993, total=   0.1s\n","[CV] C=10000.0, penalty=l2, solver=lbfgs .............................\n","[CV] . C=10000.0, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n","[CV] C=10000.0, penalty=l2, solver=lbfgs .............................\n","[CV] . C=10000.0, penalty=l2, solver=lbfgs, score=0.995, total=   0.1s\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   10.6s finished\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=3, error_score=nan,\n","             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n","                                          fit_intercept=True,\n","                                          intercept_scaling=1, l1_ratio=None,\n","                                          max_iter=100, multi_class='auto',\n","                                          n_jobs=None, penalty='l2',\n","                                          random_state=42, solver='lbfgs',\n","                                          tol=0.0001, verbose=0,\n","                                          warm_start=False),\n","             iid='deprecated', n_jobs=None,\n","             param_grid={'C': array([1.00000000e-04, 2.636...\n","       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n","       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n","       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n","       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n","                         'penalty': ['l1', 'l2'],\n","                         'solver': ['liblinear', 'sag', 'lbfgs']},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=3)"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"9CcNc611jGZp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597023773730,"user_tz":-330,"elapsed":11434,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"f21ad6f9-1358-4569-ac05-0731dd5b89d3"},"source":["grid_search.best_params_"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'liblinear'}"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"aJADFXz8jGcY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1597023775214,"user_tz":-330,"elapsed":1463,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"f9fe1e20-73ab-46cc-ba67-f9f7560ad3fc"},"source":["grid_search.best_estimator_.fit(X_strain,y_train)"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=11.288378916846883, class_weight=None, dual=False,\n","                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n","                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l1',\n","                   random_state=42, solver='liblinear', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"id":"jR-c8iNJjGe8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597023775218,"user_tz":-330,"elapsed":1455,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}}},"source":["y_pred = grid_search.best_estimator_.predict(X_stest)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"jSllXyQljGh-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1597023775221,"user_tz":-330,"elapsed":1448,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"dd6946d7-5b51-4986-b95f-8c03e0b70263"},"source":["confusion_matrix(y_test,y_pred)"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[333,   8],\n","       [  4, 955]])"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"6uhj9V24jGmI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1597023775223,"user_tz":-330,"elapsed":1441,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"be6a250a-c655-44d7-9dd0-1980b7364252"},"source":["classification_report(y_test,y_pred)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'              precision    recall  f1-score   support\\n\\n           0       0.99      0.98      0.98       341\\n           1       0.99      1.00      0.99       959\\n\\n    accuracy                           0.99      1300\\n   macro avg       0.99      0.99      0.99      1300\\nweighted avg       0.99      0.99      0.99      1300\\n'"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"markdown","metadata":{"id":"psXxGKFaDpgS","colab_type":"text"},"source":["           precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       341\n","           1       0.99      1.00      0.99       959\n","\n","    accuracy                           0.99      1300\n","   macro avg       0.99      0.99      0.99      1300\n","\n","weighted avg       0.99      0.99      0.99      1300 "]},{"cell_type":"code","metadata":{"id":"g5SJsKlgjGpg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"status":"ok","timestamp":1597023775590,"user_tz":-330,"elapsed":1798,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"9ee12fb7-5ab4-4c25-c708-9e83f6b23045"},"source":["grid_search.score"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method BaseSearchCV.score of GridSearchCV(cv=3, error_score=nan,\n","             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n","                                          fit_intercept=True,\n","                                          intercept_scaling=1, l1_ratio=None,\n","                                          max_iter=100, multi_class='auto',\n","                                          n_jobs=None, penalty='l2',\n","                                          random_state=42, solver='lbfgs',\n","                                          tol=0.0001, verbose=0,\n","                                          warm_start=False),\n","             iid='deprecated', n_jobs=None,\n","             param_grid={'C': array([1.00000000e-04, 2.636...\n","       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n","       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n","       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n","       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n","                         'penalty': ['l1', 'l2'],\n","                         'solver': ['liblinear', 'sag', 'lbfgs']},\n","             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n","             scoring=None, verbose=3)>"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"ITW_Zx8Unc0v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597024259696,"user_tz":-330,"elapsed":1391,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"1fa8cf95-b11b-4eee-9bc3-582d8c1a8808"},"source":["grid_search.cv_results_"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'mean_fit_time': array([0.00624816, 0.00026019, 0.00025137, 0.00553091, 0.01900729,\n","        0.01049956, 0.00391444, 0.00027084, 0.00026155, 0.00832629,\n","        0.01925723, 0.00895818, 0.00390124, 0.00026846, 0.00027593,\n","        0.00570671, 0.01939185, 0.00927051, 0.00472728, 0.00026234,\n","        0.00028332, 0.00785303, 0.01852512, 0.01001803, 0.01228054,\n","        0.00027593, 0.00025479, 0.00628026, 0.01592938, 0.01318431,\n","        0.00750883, 0.00028372, 0.00026147, 0.008413  , 0.01497801,\n","        0.01656262, 0.0111479 , 0.0003047 , 0.00026854, 0.00744216,\n","        0.01516747, 0.01981624, 0.02167455, 0.00029985, 0.0002691 ,\n","        0.00911999, 0.01514268, 0.02250012, 0.04848099, 0.00029683,\n","        0.00026584, 0.00979479, 0.01815486, 0.03686786, 0.07240327,\n","        0.00032997, 0.00027124, 0.01056576, 0.01960039, 0.03535501,\n","        0.07751012, 0.00029794, 0.0002803 , 0.01303172, 0.02407503,\n","        0.03281434, 0.09007176, 0.00029071, 0.00027124, 0.01066931,\n","        0.03105275, 0.03966244, 0.09419099, 0.00030279, 0.00026711,\n","        0.01399525, 0.07278744, 0.0371778 , 0.10999688, 0.00030041,\n","        0.00026822, 0.01262132, 0.10786366, 0.05702662, 0.11576962,\n","        0.00030478, 0.00027378, 0.01551493, 0.109502  , 0.06110279,\n","        0.11296757, 0.0003252 , 0.00027394, 0.01590196, 0.10696634,\n","        0.05743535, 0.11886509, 0.00029222, 0.000259  , 0.01709652,\n","        0.1026934 , 0.07049211, 0.11883601, 0.00031654, 0.00026615,\n","        0.01867143, 0.10728685, 0.0612944 , 0.12040091, 0.00031026,\n","        0.00027164, 0.0190831 , 0.1061271 , 0.06218712, 0.11749283,\n","        0.00030041, 0.00026369, 0.02135499, 0.10562189, 0.06628847]),\n"," 'mean_score_time': array([0.00070262, 0.        , 0.        , 0.00069014, 0.00069865,\n","        0.00065446, 0.00067019, 0.        , 0.        , 0.00071176,\n","        0.00078034, 0.00065215, 0.00065049, 0.        , 0.        ,\n","        0.00068235, 0.00081499, 0.00068029, 0.00066535, 0.        ,\n","        0.        , 0.00088024, 0.00155306, 0.00070278, 0.00074172,\n","        0.        , 0.        , 0.00070238, 0.00149846, 0.00064095,\n","        0.00070469, 0.        , 0.        , 0.00070453, 0.00071255,\n","        0.00067385, 0.00073457, 0.        , 0.        , 0.0007325 ,\n","        0.00071263, 0.00071454, 0.0008986 , 0.        , 0.        ,\n","        0.0007604 , 0.00078249, 0.0007484 , 0.00095312, 0.        ,\n","        0.        , 0.00093031, 0.0037636 , 0.00074212, 0.0009714 ,\n","        0.        , 0.        , 0.00083717, 0.00096695, 0.00076437,\n","        0.0009013 , 0.        , 0.        , 0.00097315, 0.00081865,\n","        0.00073957, 0.00091473, 0.        , 0.        , 0.00077097,\n","        0.00081635, 0.00074832, 0.00090019, 0.        , 0.        ,\n","        0.00075777, 0.00274396, 0.00075658, 0.00137655, 0.        ,\n","        0.        , 0.00076985, 0.00084535, 0.00071764, 0.00090106,\n","        0.        , 0.        , 0.00079934, 0.00089057, 0.00080037,\n","        0.0009555 , 0.        , 0.        , 0.00084368, 0.00085314,\n","        0.00075229, 0.00088255, 0.        , 0.        , 0.00083351,\n","        0.00414173, 0.00107336, 0.00097871, 0.        , 0.        ,\n","        0.0008556 , 0.00084909, 0.00088692, 0.00096353, 0.        ,\n","        0.        , 0.00084098, 0.00090384, 0.00078646, 0.00092626,\n","        0.        , 0.        , 0.00090861, 0.00087055, 0.00075253]),\n"," 'mean_test_score': array([0.24206267,        nan,        nan, 0.75793733, 0.75793733,\n","        0.75793733, 0.24206267,        nan,        nan, 0.75793733,\n","        0.75793733, 0.75793733, 0.24206267,        nan,        nan,\n","        0.75793733, 0.75793733, 0.75793733, 0.75793733,        nan,\n","               nan, 0.75793733, 0.75793733, 0.75793733, 0.75793733,\n","               nan,        nan, 0.75793733, 0.75793733, 0.75793733,\n","        0.84452564,        nan,        nan, 0.77429296, 0.76467172,\n","        0.76467172, 0.95035619,        nan,        nan, 0.91033351,\n","        0.90379146, 0.90379146, 0.96998212,        nan,        nan,\n","        0.96324806, 0.96324862, 0.96324862, 0.98152758,        nan,\n","               nan, 0.97690964, 0.97902666, 0.97902666, 0.98787773,\n","               nan,        nan, 0.98287455, 0.98499123, 0.98499123,\n","        0.99172629,        nan,        nan, 0.98749271, 0.98710791,\n","        0.98710791, 0.99345806,        nan,        nan, 0.98864744,\n","        0.98941704, 0.98941704, 0.99442012,        nan,        nan,\n","        0.99057167, 0.99095647, 0.99095647, 0.99442012,        nan,\n","               nan, 0.99114904, 0.99134149, 0.99134149, 0.99442012,\n","               nan,        nan, 0.99230355, 0.99191875, 0.99211109,\n","        0.99442012,        nan,        nan, 0.9936504 , 0.99230355,\n","        0.9936504 , 0.99442012,        nan,        nan, 0.99422777,\n","        0.992496  , 0.99422777, 0.99442012,        nan,        nan,\n","        0.99442012, 0.992496  , 0.99442012, 0.99442012,        nan,\n","               nan, 0.99442012, 0.992496  , 0.99442012, 0.99442012,\n","               nan,        nan, 0.99442012, 0.992496  , 0.99442012]),\n"," 'param_C': masked_array(data=[0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n","                    0.00026366508987303583, 0.00026366508987303583,\n","                    0.00026366508987303583, 0.00026366508987303583,\n","                    0.00026366508987303583, 0.00026366508987303583,\n","                    0.0006951927961775605, 0.0006951927961775605,\n","                    0.0006951927961775605, 0.0006951927961775605,\n","                    0.0006951927961775605, 0.0006951927961775605,\n","                    0.0018329807108324356, 0.0018329807108324356,\n","                    0.0018329807108324356, 0.0018329807108324356,\n","                    0.0018329807108324356, 0.0018329807108324356,\n","                    0.004832930238571752, 0.004832930238571752,\n","                    0.004832930238571752, 0.004832930238571752,\n","                    0.004832930238571752, 0.004832930238571752,\n","                    0.012742749857031334, 0.012742749857031334,\n","                    0.012742749857031334, 0.012742749857031334,\n","                    0.012742749857031334, 0.012742749857031334,\n","                    0.03359818286283781, 0.03359818286283781,\n","                    0.03359818286283781, 0.03359818286283781,\n","                    0.03359818286283781, 0.03359818286283781,\n","                    0.08858667904100823, 0.08858667904100823,\n","                    0.08858667904100823, 0.08858667904100823,\n","                    0.08858667904100823, 0.08858667904100823,\n","                    0.23357214690901212, 0.23357214690901212,\n","                    0.23357214690901212, 0.23357214690901212,\n","                    0.23357214690901212, 0.23357214690901212,\n","                    0.615848211066026, 0.615848211066026,\n","                    0.615848211066026, 0.615848211066026,\n","                    0.615848211066026, 0.615848211066026,\n","                    1.623776739188721, 1.623776739188721,\n","                    1.623776739188721, 1.623776739188721,\n","                    1.623776739188721, 1.623776739188721,\n","                    4.281332398719396, 4.281332398719396,\n","                    4.281332398719396, 4.281332398719396,\n","                    4.281332398719396, 4.281332398719396,\n","                    11.288378916846883, 11.288378916846883,\n","                    11.288378916846883, 11.288378916846883,\n","                    11.288378916846883, 11.288378916846883,\n","                    29.763514416313132, 29.763514416313132,\n","                    29.763514416313132, 29.763514416313132,\n","                    29.763514416313132, 29.763514416313132,\n","                    78.47599703514607, 78.47599703514607,\n","                    78.47599703514607, 78.47599703514607,\n","                    78.47599703514607, 78.47599703514607, 206.913808111479,\n","                    206.913808111479, 206.913808111479, 206.913808111479,\n","                    206.913808111479, 206.913808111479, 545.5594781168514,\n","                    545.5594781168514, 545.5594781168514,\n","                    545.5594781168514, 545.5594781168514,\n","                    545.5594781168514, 1438.44988828766, 1438.44988828766,\n","                    1438.44988828766, 1438.44988828766, 1438.44988828766,\n","                    1438.44988828766, 3792.690190732246, 3792.690190732246,\n","                    3792.690190732246, 3792.690190732246,\n","                    3792.690190732246, 3792.690190732246, 10000.0, 10000.0,\n","                    10000.0, 10000.0, 10000.0, 10000.0],\n","              mask=[False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False],\n","        fill_value='?',\n","             dtype=object),\n"," 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n","                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n","                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n","                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n","                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n","                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n","                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n","                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n","                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n","                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n","                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n","                    'l2', 'l2', 'l2', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2',\n","                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l1', 'l1', 'l1',\n","                    'l2', 'l2', 'l2'],\n","              mask=[False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False],\n","        fill_value='?',\n","             dtype=object),\n"," 'param_solver': masked_array(data=['liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs',\n","                    'liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs',\n","                    'liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs',\n","                    'liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs',\n","                    'liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs',\n","                    'liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs',\n","                    'liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs',\n","                    'liblinear', 'sag', 'lbfgs', 'liblinear', 'sag',\n","                    'lbfgs', 'liblinear', 'sag', 'lbfgs', 'liblinear',\n","                    'sag', 'lbfgs', 'liblinear', 'sag', 'lbfgs'],\n","              mask=[False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False,\n","                    False, False, False, False, False, False, False, False],\n","        fill_value='?',\n","             dtype=object),\n"," 'params': [{'C': 0.0001, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.0001, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.0001, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.0001, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.0001, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.0001, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.00026366508987303583, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.00026366508987303583, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.00026366508987303583, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.00026366508987303583, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.00026366508987303583, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.00026366508987303583, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.0006951927961775605, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.0006951927961775605, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.0006951927961775605, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.0006951927961775605, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.0006951927961775605, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.0006951927961775605, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.0018329807108324356, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.0018329807108324356, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.0018329807108324356, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.0018329807108324356, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.0018329807108324356, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.0018329807108324356, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.004832930238571752, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.004832930238571752, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.004832930238571752, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.004832930238571752, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.004832930238571752, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.004832930238571752, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.012742749857031334, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.012742749857031334, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.012742749857031334, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.012742749857031334, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.012742749857031334, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.012742749857031334, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.03359818286283781, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.03359818286283781, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.03359818286283781, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.03359818286283781, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.03359818286283781, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.03359818286283781, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.08858667904100823, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.08858667904100823, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.08858667904100823, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.08858667904100823, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.08858667904100823, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.08858667904100823, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.23357214690901212, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.23357214690901212, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.23357214690901212, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.23357214690901212, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.23357214690901212, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.23357214690901212, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 0.615848211066026, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 0.615848211066026, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 0.615848211066026, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 0.615848211066026, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 0.615848211066026, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 0.615848211066026, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 1.623776739188721, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 1.623776739188721, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 1.623776739188721, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 1.623776739188721, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 1.623776739188721, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 1.623776739188721, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 4.281332398719396, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 4.281332398719396, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 4.281332398719396, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 4.281332398719396, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 4.281332398719396, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 4.281332398719396, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 11.288378916846883, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 11.288378916846883, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 11.288378916846883, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 11.288378916846883, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 29.763514416313132, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 29.763514416313132, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 29.763514416313132, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 29.763514416313132, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 29.763514416313132, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 29.763514416313132, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 78.47599703514607, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 78.47599703514607, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 78.47599703514607, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 78.47599703514607, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 78.47599703514607, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 78.47599703514607, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 206.913808111479, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 206.913808111479, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 206.913808111479, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 206.913808111479, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 206.913808111479, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 206.913808111479, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 545.5594781168514, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 545.5594781168514, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 545.5594781168514, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 545.5594781168514, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 545.5594781168514, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 545.5594781168514, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 1438.44988828766, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 1438.44988828766, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 1438.44988828766, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 1438.44988828766, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 1438.44988828766, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 1438.44988828766, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 3792.690190732246, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 3792.690190732246, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 3792.690190732246, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 3792.690190732246, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 3792.690190732246, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 3792.690190732246, 'penalty': 'l2', 'solver': 'lbfgs'},\n","  {'C': 10000.0, 'penalty': 'l1', 'solver': 'liblinear'},\n","  {'C': 10000.0, 'penalty': 'l1', 'solver': 'sag'},\n","  {'C': 10000.0, 'penalty': 'l1', 'solver': 'lbfgs'},\n","  {'C': 10000.0, 'penalty': 'l2', 'solver': 'liblinear'},\n","  {'C': 10000.0, 'penalty': 'l2', 'solver': 'sag'},\n","  {'C': 10000.0, 'penalty': 'l2', 'solver': 'lbfgs'}],\n"," 'rank_test_score': array([ 78,  92,  85,  61,  61,  61,  78,  94,  82,  61,  61,  61,  78,\n","         86,  90,  61,  61,  61,  61, 118, 117,  61,  61,  61,  61, 120,\n","        112,  61,  61,  61,  57, 109, 119,  58,  59,  59,  53, 105, 102,\n","         54,  55,  55,  49,  95,  97,  52,  50,  50,  45,  98,  99,  48,\n","         46,  46,  38, 100, 101,  44,  42,  42,  28, 103, 104,  39,  40,\n","         40,  19, 106, 108,  37,  35,  35,   1, 110, 111,  34,  32,  32,\n","          1, 113, 114,  31,  29,  29,   1, 115, 116,  24,  27,  26,   1,\n","         96, 107,  17,  24,  17,   1,  89,  87,  15,  20,  15,   1,  93,\n","         81,   1,  20,   1,   1,  83,  84,   1,  20,   1,   1,  88,  91,\n","          1,  20,   1], dtype=int32),\n"," 'split0_test_score': array([0.2423543 ,        nan,        nan, 0.7576457 , 0.7576457 ,\n","        0.7576457 , 0.2423543 ,        nan,        nan, 0.7576457 ,\n","        0.7576457 , 0.7576457 , 0.2423543 ,        nan,        nan,\n","        0.7576457 , 0.7576457 , 0.7576457 , 0.7576457 ,        nan,\n","               nan, 0.7576457 , 0.7576457 , 0.7576457 , 0.7576457 ,\n","               nan,        nan, 0.7576457 , 0.7576457 , 0.7576457 ,\n","        0.84477784,        nan,        nan, 0.77380265, 0.76572418,\n","        0.76572418, 0.949221  ,        nan,        nan, 0.90709752,\n","        0.89959608, 0.89959608, 0.9728794 ,        nan,        nan,\n","        0.96306982, 0.96018465, 0.96018465, 0.98268898,        nan,\n","               nan, 0.97749567, 0.97749567, 0.97749567, 0.98730525,\n","               nan,        nan, 0.98384305, 0.98557415, 0.98557415,\n","        0.99019042,        nan,        nan, 0.98788229, 0.98730525,\n","        0.98730525, 0.99192152,        nan,        nan, 0.98788229,\n","        0.98903635, 0.98903635, 0.99307559,        nan,        nan,\n","        0.98961339, 0.99019042, 0.99019042, 0.99307559,        nan,\n","               nan, 0.98961339, 0.98961339, 0.98961339, 0.99307559,\n","               nan,        nan, 0.99076746, 0.99019042, 0.99076746,\n","        0.99307559,        nan,        nan, 0.99249856, 0.99076746,\n","        0.99249856, 0.99307559,        nan,        nan, 0.99249856,\n","        0.99076746, 0.99249856, 0.99307559,        nan,        nan,\n","        0.99307559, 0.99076746, 0.99307559, 0.99307559,        nan,\n","               nan, 0.99307559, 0.99076746, 0.99307559, 0.99307559,\n","               nan,        nan, 0.99307559, 0.99076746, 0.99307559]),\n"," 'split1_test_score': array([0.24191686,        nan,        nan, 0.75808314, 0.75808314,\n","        0.75808314, 0.24191686,        nan,        nan, 0.75808314,\n","        0.75808314, 0.75808314, 0.24191686,        nan,        nan,\n","        0.75808314, 0.75808314, 0.75808314, 0.75808314,        nan,\n","               nan, 0.75808314, 0.75808314, 0.75808314, 0.75808314,\n","               nan,        nan, 0.75808314, 0.75808314, 0.75808314,\n","        0.84815242,        nan,        nan, 0.76963048, 0.76096998,\n","        0.76096998, 0.95842956,        nan,        nan, 0.91281755,\n","        0.90473441, 0.90473441, 0.97401848,        nan,        nan,\n","        0.96882217, 0.97055427, 0.97055427, 0.98614319,        nan,\n","               nan, 0.98152425, 0.98556582, 0.98556582, 0.99076212,\n","               nan,        nan, 0.98729792, 0.99018476, 0.99018476,\n","        0.99422633,        nan,        nan, 0.99249423, 0.99076212,\n","        0.99076212, 0.9948037 ,        nan,        nan, 0.99249423,\n","        0.99249423, 0.99249423, 0.9948037 ,        nan,        nan,\n","        0.99307159, 0.99307159, 0.99307159, 0.9948037 ,        nan,\n","               nan, 0.99364896, 0.99364896, 0.99364896, 0.9948037 ,\n","               nan,        nan, 0.99422633, 0.99422633, 0.99422633,\n","        0.9948037 ,        nan,        nan, 0.9948037 , 0.99422633,\n","        0.9948037 , 0.9948037 ,        nan,        nan, 0.99538106,\n","        0.99422633, 0.99538106, 0.9948037 ,        nan,        nan,\n","        0.9948037 , 0.99422633, 0.9948037 , 0.9948037 ,        nan,\n","               nan, 0.9948037 , 0.99422633, 0.9948037 , 0.9948037 ,\n","               nan,        nan, 0.9948037 , 0.99422633, 0.9948037 ]),\n"," 'split2_test_score': array([0.24191686,        nan,        nan, 0.75808314, 0.75808314,\n","        0.75808314, 0.24191686,        nan,        nan, 0.75808314,\n","        0.75808314, 0.75808314, 0.24191686,        nan,        nan,\n","        0.75808314, 0.75808314, 0.75808314, 0.75808314,        nan,\n","               nan, 0.75808314, 0.75808314, 0.75808314, 0.75808314,\n","               nan,        nan, 0.75808314, 0.75808314, 0.75808314,\n","        0.84064665,        nan,        nan, 0.77944573, 0.76732102,\n","        0.76732102, 0.94341801,        nan,        nan, 0.91108545,\n","        0.90704388, 0.90704388, 0.9630485 ,        nan,        nan,\n","        0.95785219, 0.95900693, 0.95900693, 0.97575058,        nan,\n","               nan, 0.97170901, 0.97401848, 0.97401848, 0.98556582,\n","               nan,        nan, 0.97748268, 0.97921478, 0.97921478,\n","        0.99076212,        nan,        nan, 0.98210162, 0.98325635,\n","        0.98325635, 0.99364896,        nan,        nan, 0.98556582,\n","        0.98672055, 0.98672055, 0.99538106,        nan,        nan,\n","        0.98903002, 0.98960739, 0.98960739, 0.99538106,        nan,\n","               nan, 0.99018476, 0.99076212, 0.99076212, 0.99538106,\n","               nan,        nan, 0.99191686, 0.99133949, 0.99133949,\n","        0.99538106,        nan,        nan, 0.99364896, 0.99191686,\n","        0.99364896, 0.99538106,        nan,        nan, 0.9948037 ,\n","        0.99249423, 0.9948037 , 0.99538106,        nan,        nan,\n","        0.99538106, 0.99249423, 0.99538106, 0.99538106,        nan,\n","               nan, 0.99538106, 0.99249423, 0.99538106, 0.99538106,\n","               nan,        nan, 0.99538106, 0.99249423, 0.99538106]),\n"," 'std_fit_time': array([3.08502445e-03, 8.16987182e-06, 9.72236029e-06, 1.20502818e-04,\n","        8.20193048e-04, 1.46059657e-04, 7.28477902e-05, 1.09637988e-05,\n","        1.01824553e-05, 3.01491311e-03, 4.11926653e-04, 8.78900125e-05,\n","        8.22224993e-05, 7.98850496e-06, 7.11626098e-06, 5.10999982e-05,\n","        2.69047623e-03, 7.17821640e-05, 1.32974363e-04, 5.39947756e-06,\n","        2.34656319e-05, 1.67711737e-03, 1.48122985e-03, 2.51124177e-05,\n","        2.44967235e-03, 1.50100649e-05, 1.01719051e-05, 3.29751790e-04,\n","        1.23207073e-03, 1.25961828e-03, 7.70438447e-05, 1.36725658e-05,\n","        1.11239295e-05, 2.14483435e-03, 7.15569357e-04, 2.45989681e-03,\n","        8.86370684e-04, 1.83968942e-05, 1.91669690e-05, 3.06901568e-04,\n","        1.12062172e-03, 2.19229162e-03, 1.99637917e-03, 3.43423920e-05,\n","        1.42018690e-05, 1.49457677e-03, 7.40976202e-04, 3.35774496e-03,\n","        4.23581296e-03, 3.02826011e-05, 4.91319705e-06, 1.72750153e-03,\n","        2.60411645e-03, 7.85476865e-03, 2.53201109e-03, 4.27840131e-05,\n","        7.16931535e-06, 1.09265548e-03, 1.33629481e-03, 2.53701246e-03,\n","        3.54658102e-03, 1.56998629e-05, 6.72191952e-06, 1.89822546e-03,\n","        9.31479410e-04, 2.74650184e-03, 5.92388542e-03, 2.81726524e-05,\n","        1.71488363e-05, 1.04288319e-04, 3.69342150e-03, 6.90591169e-03,\n","        8.29890376e-03, 2.49896338e-05, 1.91432287e-05, 2.58768057e-03,\n","        2.08858578e-03, 1.02608027e-02, 1.51632017e-02, 2.83647977e-05,\n","        9.35216947e-06, 1.74904616e-04, 2.07757289e-03, 3.30666015e-02,\n","        1.36253815e-02, 1.93470307e-05, 1.29513943e-05, 1.10447993e-03,\n","        3.64666359e-04, 1.03329353e-02, 1.52579817e-02, 2.32455058e-05,\n","        9.59221285e-06, 9.44973000e-04, 3.16782470e-03, 8.54872652e-03,\n","        9.16516938e-03, 2.45785799e-05, 2.95442427e-06, 5.38207116e-04,\n","        7.44108455e-04, 1.23176695e-02, 4.72299684e-03, 2.04191126e-05,\n","        5.98531417e-06, 7.86548983e-04, 1.07598123e-03, 8.90926937e-03,\n","        1.25564793e-02, 1.28485766e-05, 1.58738955e-05, 6.45193342e-04,\n","        5.41818737e-03, 4.00778125e-03, 1.17036448e-02, 1.98675791e-05,\n","        1.95357804e-05, 3.04211550e-03, 5.01221134e-03, 7.98014554e-03]),\n"," 'std_score_time': array([2.54345435e-05, 0.00000000e+00, 0.00000000e+00, 2.55195755e-05,\n","        1.50592157e-05, 1.35304732e-05, 1.65948009e-05, 0.00000000e+00,\n","        0.00000000e+00, 4.65400286e-05, 5.96894614e-05, 6.78364987e-06,\n","        1.60767133e-05, 0.00000000e+00, 0.00000000e+00, 1.59009285e-05,\n","        5.33817489e-05, 2.53250465e-05, 1.05414690e-05, 0.00000000e+00,\n","        0.00000000e+00, 2.17312835e-04, 1.08280999e-03, 1.00708138e-05,\n","        4.91076684e-05, 0.00000000e+00, 0.00000000e+00, 4.28747055e-05,\n","        1.16561545e-03, 1.71067984e-05, 3.25836786e-05, 0.00000000e+00,\n","        0.00000000e+00, 2.62527619e-05, 2.11009048e-05, 3.39974825e-05,\n","        6.65374386e-05, 0.00000000e+00, 0.00000000e+00, 3.63212706e-05,\n","        6.76873663e-06, 1.62556484e-05, 1.49324407e-05, 0.00000000e+00,\n","        0.00000000e+00, 2.59415289e-05, 5.29593446e-05, 2.61891713e-05,\n","        4.97574999e-05, 0.00000000e+00, 0.00000000e+00, 1.82056381e-04,\n","        3.00968912e-03, 8.83186291e-06, 4.75700667e-05, 0.00000000e+00,\n","        0.00000000e+00, 4.16072110e-05, 2.05830626e-04, 2.28160476e-05,\n","        1.27657262e-05, 0.00000000e+00, 0.00000000e+00, 2.40460894e-04,\n","        3.81178215e-05, 1.45975008e-05, 1.67474792e-05, 0.00000000e+00,\n","        0.00000000e+00, 5.82692709e-05, 3.14296824e-05, 3.69922046e-05,\n","        2.04885903e-05, 0.00000000e+00, 0.00000000e+00, 6.20469815e-05,\n","        2.66911663e-03, 3.65801409e-05, 7.21298661e-04, 0.00000000e+00,\n","        0.00000000e+00, 1.39347450e-05, 6.70215881e-06, 2.77761908e-05,\n","        2.50905271e-05, 0.00000000e+00, 0.00000000e+00, 3.24110940e-05,\n","        3.90949930e-05, 1.35556566e-05, 3.25103255e-05, 0.00000000e+00,\n","        0.00000000e+00, 4.03560959e-05, 1.23062382e-05, 2.69980896e-05,\n","        2.52426120e-05, 0.00000000e+00, 0.00000000e+00, 5.13868094e-05,\n","        4.65527456e-03, 3.64760531e-04, 1.76504910e-05, 0.00000000e+00,\n","        0.00000000e+00, 1.62572025e-05, 3.11671441e-06, 2.31815044e-04,\n","        2.11770940e-05, 0.00000000e+00, 0.00000000e+00, 1.41001069e-05,\n","        7.30015212e-05, 6.83604271e-05, 9.94141628e-06, 0.00000000e+00,\n","        0.00000000e+00, 7.33936915e-05, 3.24110940e-05, 2.65722352e-05]),\n"," 'std_test_score': array([0.00020621,        nan,        nan, 0.00020621, 0.00020621,\n","        0.00020621, 0.00020621,        nan,        nan, 0.00020621,\n","        0.00020621, 0.00020621, 0.00020621,        nan,        nan,\n","        0.00020621, 0.00020621, 0.00020621, 0.00020621,        nan,\n","               nan, 0.00020621, 0.00020621, 0.00020621, 0.00020621,\n","               nan,        nan, 0.00020621, 0.00020621, 0.00020621,\n","        0.0030694 ,        nan,        nan, 0.00402203, 0.00269749,\n","        0.00269749, 0.00618078,        nan,        nan, 0.00239496,\n","        0.0031128 , 0.0031128 , 0.00492482,        nan,        nan,\n","        0.00448025, 0.0051882 , 0.0051882 , 0.00432151,        nan,\n","               nan, 0.00402843, 0.00483689, 0.00483689, 0.00215966,\n","               nan,        nan, 0.00406516, 0.0044974 , 0.0044974 ,\n","        0.00178313,        nan,        nan, 0.0042517 , 0.00306739,\n","        0.00306739, 0.00118436,        nan,        nan, 0.00287979,\n","        0.00237241, 0.00237241, 0.00097951,        nan,        nan,\n","        0.00178369, 0.00151444, 0.00151444, 0.00097951,        nan,\n","               nan, 0.00178304, 0.00169769, 0.00169769, 0.00097951,\n","               nan,        nan, 0.00143831, 0.0016978 , 0.00151382,\n","        0.00097951,        nan,        nan, 0.00094107, 0.00143831,\n","        0.00094107, 0.00097951,        nan,        nan, 0.00124525,\n","        0.00141208, 0.00124525, 0.00097951,        nan,        nan,\n","        0.00097951, 0.00141208, 0.00097951, 0.00097951,        nan,\n","               nan, 0.00097951, 0.00141208, 0.00097951, 0.00097951,\n","               nan,        nan, 0.00097951, 0.00141208, 0.00097951])}"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"dkCym8M0nqFy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597024431493,"user_tz":-330,"elapsed":1191,"user":{"displayName":"Lokesh Rao","photoUrl":"","userId":"07809147146704700800"}},"outputId":"99e00760-4491-4476-e369-776aea43cb00"},"source":["grid_search.best_score_"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9944201163218899"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"BC13icr4Euhy","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}